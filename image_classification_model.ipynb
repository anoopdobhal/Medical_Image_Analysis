{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "786dccb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "479a8466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your current GCP Project Name is: qwiklabs-gcp-04-014eea1283f0\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "export PROJECT=$(gcloud config list project --format \"value(core.project)\")\n",
    "echo \"Your current GCP Project Name is: \"${PROJECT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33c41301",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Change these to try this notebook out\n",
    "PROJECT = \"qwiklabs-gcp-04-014eea1283f0\"  # Replace with your PROJECT\n",
    "BUCKET = \"chest-xray-us-central\"   # defaults to PROJECT\n",
    "REGION = \"us-central1\"  # Replace with your REGION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7503bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"PROJECT\"] = PROJECT\n",
    "os.environ[\"BUCKET\"] = BUCKET\n",
    "os.environ[\"REGION\"] = REGION\n",
    "os.environ[\"TFVERSION\"] = \"2.1\"\n",
    "os.environ[\"PYTHONVERSION\"] = \"3.7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "472690dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n",
      "Updated property [compute/region].\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gcloud config set project ${PROJECT}\n",
    "gcloud config set compute/region ${REGION}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "177ab51a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://chest-xray-us-central/chest_xray/chest_xray_labels.csv\n",
      "gs://chest-xray-us-central/chest_xray/test/\n",
      "gs://chest-xray-us-central/chest_xray/train/\n",
      "gs://chest-xray-us-central/chest_xray/val/\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gsutil ls gs://${BUCKET}/chest_xray/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fef7c7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "\n",
    "import cv2\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from tensorflow.keras.layers import Dense, Flatten, Softmax\n",
    "\n",
    "import keras\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D,GlobalAveragePooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1e7919a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.data.ops.dataset_ops.PrefetchDataset'>\n",
      "Outoupt : \n",
      " image shape: (127, 127)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "CLASS_LABELS = ['NORMAL', 'PNEUMONIA'] \n",
    "\n",
    "def process_path(nb_class):\n",
    "    \n",
    "    def f(file_path):\n",
    "        \n",
    "        label = 0 if tf.strings.split(file_path, os.path.sep)[-2]=='NORMAL' else 1\n",
    "            \n",
    "        image = tf.io.read_file(file_path)    \n",
    "        image = tf.image.decode_jpeg(image, channels=3)\n",
    "        image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "         \n",
    "        image = tf.image.resize(image, [127, 127], method='area')\n",
    "        return image, label\n",
    "    \n",
    "    return f\n",
    "\n",
    "def reader_image(path_file, batch_size, nb_class):\n",
    "\n",
    "    list_ds = tf.data.Dataset.list_files(path_file)\n",
    "    labeled_ds = list_ds.map(process_path(nb_class))\n",
    "    \n",
    "    return labeled_ds.shuffle(100).batch(batch_size).prefetch(1)\n",
    "\n",
    "train_ds = reader_image('gs://chest-xray-us-central/chest_xray/train/*/*.jpeg', 16, 2)\n",
    "test_ds = reader_image('gs://chest-xray-us-central/chest_xray/test/*/*.jpeg', 16, 2)\n",
    "test1_ds = reader_image('gs://chest-xray-us-central/chest_xray/val/*/*.jpeg', 16, 2)\n",
    "print(type(train_ds))\n",
    "\n",
    "# We display an example\n",
    "for image, label in train_ds.take(1):\n",
    "    df = pd.DataFrame(image[0, :, :, 0].numpy())\n",
    "    \n",
    "print(f'Outoupt : \\n image shape: {df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "659d2d62",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-719308f636b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_ds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-719308f636b4>\u001b[0m in \u001b[0;36mget_numpy\u001b[0;34m(ds)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    759\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 761\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    762\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    745\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m           \u001b[0moutput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 747\u001b[0;31m           output_shapes=self._flat_output_shapes)\n\u001b[0m\u001b[1;32m    748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36miterator_get_next\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   2723\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[1;32m   2724\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"IteratorGetNext\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"output_types\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2725\u001b[0;31m         \"output_shapes\", output_shapes)\n\u001b[0m\u001b[1;32m   2726\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2727\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def get_numpy(ds):\n",
    "    \n",
    "\n",
    "    X, y = [], []\n",
    "    for images, labels in ds: \n",
    "        X.append(images)\n",
    "        y.append(labels)\n",
    "        \n",
    "    X = np.concatenate(X, axis=0)\n",
    "    X = X.reshape(X.shape[0], -1)\n",
    "    y = np.concatenate(y, axis=0)\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "X, y = get_numpy(train_ds)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "X_test, y_test = get_numpy(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c3f72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "for images, labels in train_ds.take(1):\n",
    "    for i in range(6):\n",
    "        ax = plt.subplot(3, 3, i+1)\n",
    "        plt.imshow(images[i, :, :, 0].numpy())\n",
    "        plt.title(f'Label: {CLASS_LABELS[labels[i].numpy()]}')\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04e140d",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4651e330",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.densenet import DenseNet169\n",
    "from tensorflow.keras.applications.densenet import preprocess_input as densenet_preprocess\n",
    "\n",
    "base = DenseNet169(weights = 'imagenet', include_top = False, input_shape = (127, 127, 3))\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "for layer in base.layers:\n",
    "    layer.trainable =  False # freezing densenet layers \n",
    "\n",
    "densenet_model = Sequential()\n",
    "densenet_model.add(base)\n",
    "densenet_model.add(GlobalAveragePooling2D())\n",
    "densenet_model.add(BatchNormalization())\n",
    "densenet_model.add(Dense(256, activation='relu'))\n",
    "densenet_model.add(Dropout(0.5))\n",
    "densenet_model.add(BatchNormalization())\n",
    "densenet_model.add(Dense(128, activation='relu'))\n",
    "densenet_model.add(Dropout(0.5))\n",
    "densenet_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "densenet_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54679d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "optm = Adam(lr=0.0001)\n",
    "densenet_model.compile(loss='binary_crossentropy', optimizer=optm, \n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311e9675",
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_history = densenet_model.fit(\n",
    "              train_ds,\n",
    "              validation_data=test_ds,\n",
    "              epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec025223",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n",
    "\n",
    "base = MobileNetV2(weights = 'imagenet', include_top = False, input_shape= (127, 127, 3))\n",
    "tf.keras.backend.clear_session()\n",
    "    \n",
    "for layer in base.layers:\n",
    "    layer.trainable =  False\n",
    "\n",
    "mobilenet_model = Sequential()\n",
    "mobilenet_model.add(base)\n",
    "mobilenet_model.add(GlobalAveragePooling2D())\n",
    "mobilenet_model.add(BatchNormalization())\n",
    "mobilenet_model.add(Dense(256, activation='relu'))\n",
    "mobilenet_model.add(Dropout(0.5))\n",
    "mobilenet_model.add(BatchNormalization())\n",
    "mobilenet_model.add(Dense(128, activation='relu'))\n",
    "mobilenet_model.add(Dropout(0.5))\n",
    "mobilenet_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "mobilenet_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1e88de",
   "metadata": {},
   "outputs": [],
   "source": [
    "optm = Adam(lr=0.0001)\n",
    "mobilenet_model.compile(loss='binary_crossentropy', optimizer=optm, \n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e12a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "mobilenet_history = mobilenet_model.fit(\n",
    "              train_ds,\n",
    "              validation_data=test_ds,\n",
    "              epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f94b871",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf1077c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.merge import concatenate\n",
    "from keras.layers import Input\n",
    "import tensorflow as tf\n",
    "\n",
    "input_shape = (224,224,3)\n",
    "input_layer = Input(shape = (224, 224, 3))\n",
    "\n",
    "#first model\n",
    "base_mobilenet = MobileNetV2(weights = 'imagenet', include_top = False, input_shape = input_shape)\n",
    "base_densenet = DenseNet169(weights = 'imagenet', include_top = False, input_shape = input_shape)\n",
    "\n",
    "for layer in base_mobilenet.layers:\n",
    "    layer.trainable =  False\n",
    "for layer in base_densenet.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "model_mobilenet = base_mobilenet(input_layer)\n",
    "model_mobilenet = GlobalAveragePooling2D()(model_mobilenet)\n",
    "output_mobilenet = Flatten()(model_mobilenet)\n",
    "\n",
    "model_densenet = base_densenet(input_layer)\n",
    "model_densenet = GlobalAveragePooling2D()(model_densenet)\n",
    "output_densenet = Flatten()(model_densenet)\n",
    "\n",
    "merged = tf.keras.layers.Concatenate()([output_mobilenet, output_densenet]) \n",
    "\n",
    "x = BatchNormalization()(merged)\n",
    "x = Dense(256,activation = 'relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(128,activation = 'relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(1, activation = 'sigmoid')(x)\n",
    "stacked_model = tf.keras.models.Model(inputs = input_layer, outputs = x)\n",
    "stacked_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e524a6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "optm = Adam(lr=0.0001)\n",
    "stacked_model.compile(loss='binary_crossentropy', optimizer=optm, \n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9347dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_history = stacked_model.fit( \n",
    "                train_ds,\n",
    "              validation_data=test_ds,\n",
    "              epochs=20)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-1.m71",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-1:m71"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
